{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This part describe how to refine the mix-grained dataset to fine grained dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle as pkl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'/home/shensy/Code/python/doduo/data/ssy_test.coltype.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        table_id                                             labels  \\\n",
      "0      6675886-1                      [sports.sports_league_season]   \n",
      "1      6675886-1                                    [people.person]   \n",
      "2      6675886-1                        [organization.organization]   \n",
      "3      6675886-1                      [business.business_operation]   \n",
      "4      6675886-1                               [automotive.company]   \n",
      "...          ...                                                ...   \n",
      "1870  40723972-2  [location.administrative_division, location.lo...   \n",
      "1871  40723972-2                        [organization.organization]   \n",
      "1872  40723972-2  [government.political_party, organization.orga...   \n",
      "1873  40723972-2                        [organization.organization]   \n",
      "1874  40723972-2  [government.political_party, organization.orga...   \n",
      "\n",
      "                                                   data  \\\n",
      "0     1998 1999 2000 2001 2002 2003 2004 2005 2006 2...   \n",
      "1     Jackie Stewart Adrian Fernández Adrian Fernánd...   \n",
      "2     Mecom Racing Team Patrick Racing Patrick Racin...   \n",
      "3     Lola Reynard Reynard Lola Lola Lola Dallara Da...   \n",
      "4     Ford Ford - Cosworth Ford - Cosworth Ford - Co...   \n",
      "...                                                 ...   \n",
      "1870  KIL JAF JAF MUL MAN JAF MAN VAV VAV MUL JAF JA...   \n",
      "1871  ITAK ITAK EPRLF ACMC TELO ITAK TELO TULF EPRLF...   \n",
      "1872  TNA TNA TNA TNA UPFA TNA TNA TNA TNA TNA UPFA ...   \n",
      "1873  ITAK ITAK EPRLF ACMC TELO ITAK TELO TULF EPRLF...   \n",
      "1874  TNA TNA TNA TNA UPFA TNA TNA TNA TNA TNA UPFA ...   \n",
      "\n",
      "                                              label_ids            header  \\\n",
      "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     season season   \n",
      "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     driver driver   \n",
      "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         team team   \n",
      "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   chassis chassis   \n",
      "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     engine engine   \n",
      "...                                                 ...               ...   \n",
      "1870  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          district   \n",
      "1871  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     elected party   \n",
      "1872  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  elected alliance   \n",
      "1873  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     current party   \n",
      "1874  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  current alliance   \n",
      "\n",
      "                                                   type  \n",
      "0     {'Champ_Car_season': 5, 'IndyCar_Series_season...  \n",
      "1     {'http://dbpedia.org/ontology/Person': 10, 'ht...  \n",
      "2     {'http://dbpedia.org/ontology/SoccerClub': 14,...  \n",
      "3     {'http://dbpedia.org/ontology/Company': 15, 'h...  \n",
      "4     {'http://dbpedia.org/ontology/Company': 15, 'h...  \n",
      "...                                                 ...  \n",
      "1870  {'http://dbpedia.org/ontology/Place': 21, 'htt...  \n",
      "1871  {'http://dbpedia.org/ontology/Organisation': 1...  \n",
      "1872  {'http://dbpedia.org/ontology/Organisation': 1...  \n",
      "1873  {'http://dbpedia.org/ontology/Organisation': 1...  \n",
      "1874  {'http://dbpedia.org/ontology/Organisation': 1...  \n",
      "\n",
      "[1875 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "with open (path, \"rb\") as f:\n",
    "    turl_type_test = pkl.load(f)\n",
    "print(turl_type_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coarse-grained type like `organization.organization` exist, drop them to ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_list = ['people.person','location.location','sports.sport','time.event', 'sports.pro_athlete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_idx = []\n",
    "failed_table = []\n",
    "\n",
    "for idx, row in turl_type_test.iterrows():\n",
    "    if len(row.labels)>2:\n",
    "        del_idx.append(idx)\n",
    "        failed_table.append(row.table_id)\n",
    "    if row.labels[0] in exclude_list:\n",
    "        del_idx.append(idx)      \n",
    "        \n",
    "for idx, row in turl_type_test.iterrows(): \n",
    "    if row.table_id in failed_table:\n",
    "        del_idx.append(idx)     \n",
    "        \n",
    "del_idx = list(set(del_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1361"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = turl_type_test.drop(del_idx)\n",
    "\n",
    "ff = open(\"../data/fine-grained_WikiTables.pkl\",\"wb\")\n",
    "pkl.dump(test_df, ff)\n",
    "ff.close\n",
    "\n",
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.groupby(\"table_id\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tv.tv_actor\n",
    "location.us_state\n",
    "music.composer\n",
    "sports.boxer\n",
    "automotive.company\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create csv for boss to read "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6675886-1',\n",
       " 'indy japan 300',\n",
       " 6675886,\n",
       " 'past winners',\n",
       " ' usac championship car history (non-championship, fuji )',\n",
       " ['season season', 'chassis chassis', 'engine engine'],\n",
       " [[[[2, 0], [5710555, '1998']],\n",
       "   [[3, 0], [6498428, '1999']],\n",
       "   [[4, 0], [11056278, '2000']],\n",
       "   [[5, 0], [10637245, '2001']],\n",
       "   [[6, 0], [9014994, '2002']],\n",
       "   [[8, 0], [4485956, '2003']],\n",
       "   [[9, 0], [4479387, '2004']],\n",
       "   [[10, 0], [2454550, '2005']],\n",
       "   [[11, 0], [2696531, '2006']],\n",
       "   [[12, 0], [6235033, '2007']],\n",
       "   [[13, 0], [6939922, '2008']],\n",
       "   [[14, 0], [13512105, '2009']],\n",
       "   [[15, 0], [16099880, '2010']],\n",
       "   [[16, 0], [19850806, '2011']]],\n",
       "  [[[0, 3], [676392, 'Lola']],\n",
       "   [[2, 3], [30865876, 'Reynard']],\n",
       "   [[3, 3], [30865876, 'Reynard']],\n",
       "   [[4, 3], [676392, 'Lola']],\n",
       "   [[5, 3], [676392, 'Lola']],\n",
       "   [[6, 3], [676392, 'Lola']],\n",
       "   [[8, 3], [1226646, 'Dallara']],\n",
       "   [[9, 3], [1226646, 'Dallara']],\n",
       "   [[10, 3], [1226646, 'Dallara']],\n",
       "   [[11, 3], [1226646, 'Dallara']],\n",
       "   [[12, 3], [1226646, 'Dallara']],\n",
       "   [[13, 3], [1226646, 'Dallara']],\n",
       "   [[14, 3], [1226646, 'Dallara']],\n",
       "   [[15, 3], [1226646, 'Dallara']],\n",
       "   [[16, 3], [1226646, 'Dallara']]],\n",
       "  [[[0, 4], [30433662, 'Ford']],\n",
       "   [[2, 4], [30433662, 'Ford - Cosworth']],\n",
       "   [[3, 4], [30433662, 'Ford - Cosworth']],\n",
       "   [[4, 4], [30433662, 'Ford - Cosworth']],\n",
       "   [[5, 4], [30433662, 'Ford - Cosworth']],\n",
       "   [[6, 4], [30984, 'Toyota']],\n",
       "   [[8, 4], [30984, 'Toyota']],\n",
       "   [[9, 4], [13729, 'Honda']],\n",
       "   [[10, 4], [13729, 'Honda']],\n",
       "   [[11, 4], [13729, 'Honda']],\n",
       "   [[12, 4], [13729, 'Honda']],\n",
       "   [[13, 4], [13729, 'Honda']],\n",
       "   [[14, 4], [13729, 'Honda']],\n",
       "   [[15, 4], [13729, 'Honda']],\n",
       "   [[16, 4], [13729, 'Honda']]]],\n",
       " [['sports.sports_league_season'],\n",
       "  ['business.business_operation'],\n",
       "  ['automotive.company']]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from json to csv\n",
    "with open('../data/fine-grained_WikiTables.json', 'r', encoding=\"utf8\") as f:\n",
    "    example = json.load(f)[0]\n",
    "display(example)\n",
    "len(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2dataframe(list_table):\n",
    "    table_idx, page_title, table_id, headline, table_name, header, data, gd_header = list_table\n",
    "    table_idx=table_idx.split('-')[-1]\n",
    "    list_data=[]\n",
    "    for row in data:\n",
    "        temp_row=[]\n",
    "        for cell in row:\n",
    "            temp_row.append(cell[-1][-1]) \n",
    "        list_data.append(temp_row)\n",
    "\n",
    "    list_data = map(list, zip(*list_data))\n",
    "    df=pd.DataFrame(list_data, columns = header)\n",
    "    return table_idx, page_title, table_id, headline, table_name, header, df, gd_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['indy japan 300'], ['past winners'], [' usac championship car history (non-championship, fuji )'], ['sports.sports_league_season', 'business.business_operation', 'automotive.company'], ['season season', 'chassis chassis', 'engine engine'], ['1998', 'Lola', 'Ford'], ['1999', 'Reynard', 'Ford - Cosworth'], ['2000', 'Reynard', 'Ford - Cosworth'], ['2001', 'Lola', 'Ford - Cosworth'], ['2002', 'Lola', 'Ford - Cosworth'], ['2003', 'Lola', 'Toyota'], ['2004', 'Dallara', 'Toyota'], ['2005', 'Dallara', 'Honda'], ['2006', 'Dallara', 'Honda'], ['2007', 'Dallara', 'Honda'], ['2008', 'Dallara', 'Honda'], ['2009', 'Dallara', 'Honda'], ['2010', 'Dallara', 'Honda'], ['2011', 'Dallara', 'Honda']]\n"
     ]
    }
   ],
   "source": [
    "with open('../data/fine-grained_WikiTables.json', 'r', encoding=\"utf8\") as f:\n",
    "    tables = json.load(f)\n",
    "    \n",
    "for tab in tables:\n",
    "    table_idx, page_title, table_id, headline, table_name, header, df, gd_header = list2dataframe(tab)\n",
    "    gd = []\n",
    "    for h in gd_header:\n",
    "        gd += h\n",
    "    \n",
    "    int_tab = [[\"***PAGE TITLE***\"],[page_title],\n",
    "               [\"***HEADLINE***\"], [headline], \n",
    "               [\"***TABLE NAME***\"],[table_name],\n",
    "               [\"***GROUND TRUTH***\"],gd, \n",
    "               [\"***HEADER***\"],header,[\"***TABLE CONTENT***\"]] + np.array(df).tolist()+[[]]\n",
    "    print(int_tab)\n",
    "    with open('../data/fine-grined_WikiTables.csv', \"a\", encoding='utf8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(int_tab)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doduo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39932664a524d94cab53f4c44d679cbe80a2c2f17c62037c31679bd80183caea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
